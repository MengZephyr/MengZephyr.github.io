---
layout: post
title: Deep Detail Enhancement for Any Garment
description: # Add post description (optional)
img: p5.jpg # Add image post (optional)
fig-caption: # Add figcaption (optional)
tags: [Publication]
---
<center>Meng Zhang, Tuanfeng Wang, Duygu Ceylan, Niloy J. Mitra</center>

**Eurographics 2021 <span style="color:blue"> (Honorable Mention Best Paper Award) </span>**

## Abstract
Creating fine garment details requires significant efforts and huge computational resources. In contrast, a coarse shape may be easy to acquire in many scenarios (e.g., via low-resolution physically-based simulation, linear blend skinning driven by skeletal motion, portable scanners). In this paper, we show how to enhance, in a data-driven manner, rich yet plausible details starting from a coarse garment geometry. Once the parameterization of the garment is given, we formulate the task as a style transfer problem over the space of associated normal maps. In order to facilitate generalization across garment types and character motions, we introduce a patch-based formulation, that produces high-resolution details by matching a Gram matrix based style loss, to hallucinate geometric details (i.e., wrinkle density and shape). We extensively evaluate our method on a variety of production scenarios and show that our method is simple, light-weight, efficient, and generalizes across underlying garment types, sewing patterns, and body motion. 

[Pdf](https://arxiv.org/pdf/2008.04367.pdf){:target="_blank"}, 
[Webpage](http://geometry.cs.ucl.ac.uk/projects/2021/DeepDetailEnhance/){:target="_blank"}
[Video](https://www.youtube.com/watch?v=zDdl3Ufbq50&t){:target="_blank"}
[Paper talk](https://www.youtube.com/watch?v=9kqQpnLZVb4&t){:target="_blank"}

## BibTex
@inproceedings{zhang2021deep,
  title={Deep detail enhancement for any garment},
  author={Zhang, Meng and Wang, Tuanfeng and Ceylan, Duygu and Mitra, Niloy J},
  booktitle={Computer Graphics Forum},
  volume={40},
  number={2},
  pages={399--411},
  year={2021},
  organization={Wiley Online Library}
}


